apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: stakater-logging-elasticsearch-curator
  namespace: logging
spec:
  releaseName: stakater-logging-elasticsearch-curator
  chart:
    repository: https://kubernetes-charts.storage.googleapis.com
    name: elasticsearch-curator
    version: 2.1.0
  values:
    cronjob:
      # At 06:30 every day
      schedule: "30 6 * * *"

    configMaps:
      action_file_yml: |-
        ---
        actions:
          1:
            action: delete_indices
            description: "Clean up ES by deleting old indices"
            options:
              timeout_override:
              continue_if_exception: False
              disable_action: False
              ignore_empty_list: True
            filters:
            - filtertype: age
              source: name
              direction: older
              timestring: '%Y.%m.%d'
              unit: days
              unit_count: 30
              field:
              stats_result:
              epoch:
              exclude: False
          # 2:
          #   action: snapshot
          #   description: "Create snapshot"
          #   filters:
          #   - filtertype: pattern
          #     kind: prefix
          #     value: logstash-
          #   - filtertype: age
          #     source: name
          #     direction: older
          #     timestring: '%Y.%m.%d'
          #     unit: days
          #     unit_count: 1
          #     options:
          #       disable_action: false
          #       ignore_unavailable: false
          #       include_global_state: true
          #       name: curator-%Y.%m.%d
          #       partial: false
          #       repository: "logger-es"
          #       skip_repo_fs_check: false
          #       wait_for_completion: true
          # 3:
          #   action: restore
          #   description: "Restore from snapshot"
          #   options:
          #     repository: "logger-es"
          #     # If name is blank, the most recent snapshot by age will be selected
          #     name:
          #     # If indices is blank, all indices in the snapshot will be restored
          #     indices:
          #     include_aliases: False
          #     ignore_unavailable: False
          #     include_global_state: False
          #     partial: False
          #     rename_pattern:
          #     rename_replacement:
          #     extra_settings:
          #     wait_for_completion: True
          #     skip_repo_fs_check: True
          #     disable_action: false
          #   filters:
          #   - filtertype: pattern
          #     kind: prefix
          #     value: curator-
          #   - filtertype: state
          #     state: SUCCESS

      config_yml: |-
        ---
        client:
          hosts:
            - elasticsearch-master.logging
          port: 9200
          url_prefix:
          use_ssl: False
          certificate:
          client_cert:
          client_key:
          ssl_no_validate: True
          http_auth:
          timeout: 30
          master_only: False
        logging:
          loglevel: INFO
          logfile:
          logformat: default
          blacklist: ['elasticsearch', 'urllib3']
    # extraInitContainers:
    #   elasticsearch-s3-repository:
    #     image: jwilder/dockerize:latest
    #     imagePullPolicy: "IfNotPresent"
    #     command:
    #       - "/bin/sh"
    #       - "-c"
    #     args:
    #       - |
    #         ES_HOST=elasticsearch-client.logging
    #         ES_PORT=9200
    #         ES_REPOSITORY=logger-es
    #         S3_REGION=ap-southeast-1
    #         S3_BUCKET=pliro-monitoring-logs-backup
    #         S3_BASE_PATH=/
    #         S3_COMPRESS=true
    #         S3_STORAGE_CLASS=standard
    #         apk add curl --no-cache && \
    #         dockerize -wait http://${ES_HOST}:${ES_PORT} --timeout 120s && \
    #         cat <<EOF | curl -sS -XPUT -H "Content-Type: application/json" -d @- http://${ES_HOST}:${ES_PORT}/_snapshot/${ES_REPOSITORY} \
    #         {
    #           "type": "s3",
    #           "settings": {
    #             "bucket": "${S3_BUCKET}",
    #             "base_path": "${S3_BASE_PATH}",
    #             "region": "${S3_REGION}"
    #             }
    #         }
